{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity Score Estimation: P(Email | Customer Features)\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "In this notebook, we will:\n",
    "1. **Understand propensity scores** - What they are and why they matter\n",
    "2. **Estimate propensity scores** - Build a logistic regression model\n",
    "3. **Diagnose the model** - Check common support and model quality\n",
    "4. **Visualize results** - Create diagnostic plots\n",
    "5. **Save for downstream analysis** - Ready for matching, weighting, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Background: What are Propensity Scores?\n",
    "\n",
    "The **propensity score** is the probability of receiving treatment given observed covariates:\n",
    "\n",
    "```\ne(x) = P(T = 1 | X)\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **T**: Treatment indicator (1 = received email, 0 = no email)\n",
    "- **X**: Observed customer characteristics (confounders)\n",
    "- **e(x)**: Propensity score (ranges from 0 to 1)\n",
    "\n",
    "### Why Propensity Scores?\n",
    "\n",
    "Propensity scores allow us to:\n",
    "1. **Reduce dimensionality**: Replace multiple covariates with single score\n",
    "2. **Enable matching**: Match treated and control units with similar scores\n",
    "3. **Weight observations**: Use inverse probability weighting (IPW)\n",
    "4. **Stratify**: Create strata with balanced covariates\n",
    "\n",
    "### Key Assumptions\n",
    "\n",
    "1. **Unconfoundedness**: T ‚üÇ Y(0), Y(1) | X\n",
    "   - No unobserved confounders\n",
    "2. **Common Support**: P(T=1 | X) ‚àà (0, 1) for all X\n",
    "   - Everyone has some chance of receiving treatment\n",
    "3. **Correct Model**: Propensity model is correctly specified\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")\n",
    "\n",
    "# Load data\n",
    "data_path = '/Users/dustinober/Projects/Causal-Impact-of-Email-Marketing-on-Purchase-Behavior/data/processed/data_with_propensity_scores.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Data loaded: {data.shape}\")\n",
    "print(f\"   Columns: {list(data.columns)}\")\n",
    "\n",
    "# Quick summary\n",
    "print(f\"\\nüìä Data Summary:\")\n",
    "print(f\"   Total observations: {len(data):,}\")\n",
    "print(f\"   Treatment rate: {data['received_email'].mean():.1%}\")\n",
    "print(f\"   Purchase rate: {data['purchased_this_week_observed'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Define Confounding Variables\n",
    "\n",
    "These are the variables that affect **both** email assignment AND purchase behavior.\n",
    "They create confounding bias in naive comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for propensity model\n",
    "features = [\n",
    "    'days_since_last_purchase',     # Recency: How recently did they buy?\n",
    "    'total_past_purchases',         # Frequency: How many purchases?\n",
    "    'avg_order_value',              # Monetary: How much do they spend?\n",
    "    'customer_tenure_weeks',        # Tenure: How long have they been a customer?\n",
    "    'rfm_score'                     # Composite RFM score\n",
    "]\n",
    "\n",
    "print(\"üìã Confounding Variables (X):\")\n",
    "print(\"-\"*70)\n",
    "for i, feature in enumerate(features, 1):\n",
    "    print(f\"   {i}. {feature}\")\n",
    "\n",
    "print(\"\\nüí° Why these matter:\")\n",
    "print(\"   ‚Ä¢ Recent buyers ‚Üí More likely to receive emails\")\n",
    "print(\"   ‚Ä¢ Frequent buyers ‚Üí More likely to receive emails\")\n",
    "print(\"   ‚Ä¢ High-value buyers ‚Üí More likely to receive emails\")\n",
    "print(\"   ‚Ä¢ These differences bias naive comparisons!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 1: Explore the Confounders\n",
    "\n",
    "Let's examine the relationships between these variables and email receipt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare means by treatment group\n",
    "treated = data[data['received_email']]\n",
    "control = data[~data['received_email']]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFOUNDER COMPARISON: TREATED vs CONTROL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Feature':<30} {'No Email':<15} {'Email':<15} {'Difference':<15}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for feature in features:\n",
    "    control_mean = control[feature].mean()\n",
    "    treated_mean = treated[feature].mean()\n",
    "    difference = treated_mean - control_mean\n",
    "    \n",
    "    print(f\"{feature:<30} {control_mean:<15.2f} {treated_mean:<15.2f} {difference:<+15.2f}\")\n",
    "\n",
    "print(\"\\nüí° Observation:\")\n",
    "print(\"   Email recipients have systematically different characteristics!\")\n",
    "print(\"   ‚Üí This creates CONFOUNDING BIAS in naive comparisons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 2: Estimate Propensity Scores\n",
    "\n",
    "Now we'll fit a logistic regression model to estimate P(email | X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = data[features].values\n",
    "treatment = data['received_email'].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit logistic regression\n",
    "print(\"\\nüîÑ Fitting logistic regression...\")\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model.fit(X_scaled, treatment)\n",
    "\n",
    "# Predict propensity scores\n",
    "propensity_scores = model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "# Add to dataframe (if not already there)\n",
    "data['propensity_score'] = propensity_scores\n",
    "\n",
    "# Model performance\n",
    "auc = roc_auc_score(treatment, propensity_scores)\n",
    "print(f\"   ‚úÖ Model fitted\")\n",
    "print(f\"   üìà AUC: {auc:.3f}\")\n",
    "\n",
    "if auc > 0.7:\n",
    "    performance = \"Good\"\n",
    "elif auc > 0.6:\n",
    "    performance = \"Fair\"\n",
    "else:\n",
    "    performance = \"Poor\"\n",
    "\n",
    "print(f\"   üìä Performance: {performance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Step 3: Interpret Model Coefficients\n",
    "\n",
    "Let's understand what drives email assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COEFFICIENTS AND ODDS RATIOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Feature':<30} {'Coefficient':<15} {'Odds Ratio':<15} {'Effect'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for feature, coef in zip(features, model.coef_[0]):\n",
    "    odds_ratio = np.exp(coef)\n",
    "    direction = \"‚Üë\" if coef > 0 else \"‚Üì\"\n",
    "    \n",
    "    if abs(coef) > 0.3:\n",
    "        strength = \"Strong\"\n",
    "    elif abs(coef) > 0.1:\n",
    "        strength = \"Moderate\"\n",
    "    else:\n",
    "        strength = \"Weak\"\n",
    "    \n",
    "    print(f\"{feature:<30} {coef:<+15.4f} {odds_ratio:<15.3f} {direction} {strength}\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"   ‚Ä¢ Odds Ratio > 1: Higher feature ‚Üí Higher probability of email\")\n",
    "print(\"   ‚Ä¢ Odds Ratio < 1: Higher feature ‚Üí Lower probability of email\")\n",
    "print(\"   ‚Ä¢ Days since last purchase has STRONGEST effect\")\n",
    "print(\"   ‚Ä¢ Recent buyers (low days) are MUCH more likely to get emails!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìè Step 4: Propensity Score Distribution\n",
    "\n",
    "Let's examine the distribution of propensity scores by treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics\n",
    "treated_scores = data[data['received_email']]['propensity_score']\n",
    "control_scores = data[~data['received_email']]['propensity_score']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROPENSITY SCORE SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Statistic':<20} {'Treated (Email)':<20} {'Control (No Email)':<20}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Mean':<20} {treated_scores.mean():<20.4f} {control_scores.mean():<20.4f}\")\n",
    "print(f\"{'Std':<20} {treated_scores.std():<20.4f} {control_scores.std():<20.4f}\")\n",
    "print(f\"{'Min':<20} {treated_scores.min():<20.4f} {control_scores.min():<20.4f}\")\n",
    "print(f\"{'25th percentile':<20} {treated_scores.quantile(0.25):<20.4f} {control_scores.quantile(0.25):<20.4f}\")\n",
    "print(f\"{'Median':<20} {treated_scores.median():<20.4f} {control_scores.median():<20.4f}\")\n",
    "print(f\"{'75th percentile':<20} {treated_scores.quantile(0.75):<20.4f} {control_scores.quantile(0.75):<20.4f}\")\n",
    "print(f\"{'Max':<20} {treated_scores.max():<20.4f} {control_scores.max():<20.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ Key Finding:\")\n",
    "print(f\"   Mean difference: {treated_scores.mean() - control_scores.mean():.4f}\")\n",
    "print(f\"   ‚Üí Email recipients have higher propensity scores\")\n",
    "print(f\"   ‚Üí This is EXPECTED - we model P(email | X)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 5: Visualize Propensity Scores\n",
    "\n",
    "Create comprehensive diagnostic plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diagnostic plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Histogram\n",
    "axes[0, 0].hist(control_scores, bins=50, alpha=0.7, label='No Email',\n",
    "                color='lightcoral', density=True, edgecolor='black')\n",
    "axes[0, 0].hist(treated_scores, bins=50, alpha=0.7, label='Email',\n",
    "                color='lightgreen', density=True, edgecolor='black')\n",
    "axes[0, 0].set_xlabel('Propensity Score')\n",
    "axes[0, 0].set_ylabel('Density')\n",
    "axes[0, 0].set_title('Distribution by Treatment Group', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Box plot\n",
    "box_data = [control_scores, treated_scores]\n",
    "bp = axes[0, 1].boxplot(box_data, tick_labels=['No Email', 'Email'],\n",
    "                        patch_artist=True, notch=True)\n",
    "bp['boxes'][0].set_facecolor('lightcoral')\n",
    "bp['boxes'][1].set_facecolor('lightgreen')\n",
    "axes[0, 1].set_ylabel('Propensity Score')\n",
    "axes[0, 1].set_title('Box Plots', fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: ROC Curve\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, _ = roc_curve(treatment, propensity_scores)\n",
    "axes[0, 2].plot(fpr, tpr, color='darkgreen', linewidth=2,\n",
    "                label=f'ROC (AUC = {auc:.3f})')\n",
    "axes[0, 2].plot([0, 1], [0, 1], 'r--', alpha=0.7, label='Random')\n",
    "axes[0, 2].set_xlabel('False Positive Rate')\n",
    "axes[0, 2].set_ylabel('True Positive Rate')\n",
    "axes[0, 2].set_title('ROC Curve', fontweight='bold')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Feature importance\n",
    "abs_coef = np.abs(model.coef_[0])\n",
    "colors = ['red' if c < 0 else 'green' for c in model.coef_[0]]\n",
    "bars = axes[1, 0].barh(features, model.coef_[0], color=colors, alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].set_xlabel('Coefficient')\n",
    "axes[1, 0].set_title('Feature Coefficients', fontweight='bold')\n",
    "axes[1, 0].axvline(0, color='black', linestyle='-', alpha=0.5)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, coef in zip(bars, model.coef_[0]):\n",
    "    axes[1, 0].text(coef + (0.005 if coef >= 0 else -0.005), bar.get_y() + bar.get_height()/2,\n",
    "                    f'{coef:.3f}', ha='left' if coef >= 0 else 'right', va='center', fontsize=9)\n",
    "\n",
    "# Plot 5: QQ plot\n",
    "from scipy import stats\n",
    "treated_quantiles = np.percentile(treated_scores, np.linspace(0, 100, 100))\n",
    "control_quantiles = np.percentile(control_scores, np.linspace(0, 100, 100))\n",
    "axes[1, 1].scatter(control_quantiles, treated_quantiles, alpha=0.6, s=20)\n",
    "min_val = min(treated_quantiles.min(), control_quantiles.min())\n",
    "max_val = max(treated_quantiles.max(), control_quantiles.max())\n",
    "axes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Control Quantiles')\n",
    "axes[1, 1].set_ylabel('Treated Quantiles')\n",
    "axes[1, 1].set_title('Q-Q Plot', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: CDF\n",
    "axes[1, 2].hist(control_scores, bins=50, cumulative=True, density=True,\n",
    "                alpha=0.7, label='No Email', color='lightcoral',\n",
    "                histtype='step', linewidth=2)\n",
    "axes[1, 2].hist(treated_scores, bins=50, cumulative=True, density=True,\n",
    "                alpha=0.7, label='Email', color='lightgreen',\n",
    "                histtype='step', linewidth=2)\n",
    "axes[1, 2].set_xlabel('Propensity Score')\n",
    "axes[1, 2].set_ylabel('Cumulative Probability')\n",
    "axes[1, 2].set_title('Cumulative Distribution', fontweight='bold')\n",
    "axes[1, 2].legend()\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Diagnostic plots created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Step 6: Check Common Support (Overlap)\n",
    "\n",
    "Common support means treated and control units have overlapping propensity scores.\n",
    "Units without overlap cannot be matched and should be excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check overlap\n",
    "min_treated = treated_scores.min()\n",
    "max_treated = treated_scores.max()\n",
    "min_control = control_scores.min()\n",
    "max_control = control_scores.max()\n",
    "\n",
    "overlap_min = max(min_treated, min_control)\n",
    "overlap_max = min(max_treated, max_control)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMMON SUPPORT CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìè Propensity Score Ranges:\")\n",
    "print(f\"   Treated (email):     [{min_treated:.4f}, {max_treated:.4f}]\")\n",
    "print(f\"   Control (no email):  [{min_control:.4f}, {max_control:.4f}]\")\n",
    "print(f\"   Overlap region:      [{overlap_min:.4f}, {overlap_max:.4f}]\")\n",
    "\n",
    "# Units outside overlap\n",
    "no_support = ((data['propensity_score'] < overlap_min) | \n",
    "              (data['propensity_score'] > overlap_max)).sum()\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Units without common support: {no_support:,} ({no_support/len(data)*100:.2f}%)\")\n",
    "\n",
    "if no_support > 0:\n",
    "    print(f\"   These units should be excluded from matching analysis\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Perfect overlap - all units can be matched!\")\n",
    "\n",
    "# Visualize overlap\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(control_scores, bins=50, alpha=0.7, label='No Email', color='lightcoral', density=True)\n",
    "plt.hist(treated_scores, bins=50, alpha=0.7, label='Email', color='lightgreen', density=True)\n",
    "plt.axvline(overlap_min, color='blue', linestyle='--', linewidth=2, label='Overlap Region')\n",
    "plt.axvline(overlap_max, color='blue', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Propensity Score Overlap', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Show common support as shaded region\n",
    "x = np.linspace(data['propensity_score'].min(), data['propensity_score'].max(), 100)\n",
    "from scipy.stats import gaussian_kde\n",
    "kde_control = gaussian_kde(control_scores)\n",
    "kde_treated = gaussian_kde(treated_scores)\n",
    "\n",
    "plt.fill_between(x, kde_control(x), alpha=0.5, color='lightcoral', label='No Email')\n",
    "plt.fill_between(x, kde_treated(x), alpha=0.5, color='lightgreen', label='Email')\n",
    "plt.axvspan(overlap_min, overlap_max, alpha=0.2, color='blue', label='Common Support')\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Common Support Region', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Step 7: Identify Extreme Scores\n",
    "\n",
    "Extreme propensity scores (near 0 or 1) can cause problems in matching.\n",
    "Let's identify units with very low or very high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify extreme scores\n",
    "low_thresholds = [1, 5]  # Bottom 1% and 5%\n",
    "high_thresholds = [95, 99]  # Top 5% and 1%\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXTREME PROPENSITY SCORES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Score Thresholds:\")\n",
    "print(f\"{'Threshold':<15} {'Value':<15} {'Count':<15} {'Percentage'}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for p in low_thresholds + high_thresholds:\n",
    "    val = np.percentile(data['propensity_score'], p)\n",
    "    count = (data['propensity_score'] <= val).sum() if p <= 5 else (data['propensity_score'] >= val).sum()\n",
    "    pct = count / len(data) * 100\n",
    "    print(f\"{p}th percentile:    {val:<15.4f} {count:<15,} {pct:<15.2f}%\")\n",
    "\n",
    "# Units near boundaries\n",
    "near_zero = (data['propensity_score'] < 0.01).sum()\n",
    "near_one = (data['propensity_score'] > 0.99).sum()\n",
    "\n",
    "print(f\"\\nüéØ Near Boundaries:\")\n",
    "print(f\"   Score < 0.01: {near_zero:,} units ({near_zero/len(data)*100:.3f}%)\")\n",
    "print(f\"   Score > 0.99: {near_one:,} units ({near_one/len(data)*100:.3f}%)\")\n",
    "print(f\"   Total: {near_zero + near_one:,} units ({(near_zero + near_one)/len(data)*100:.3f}%)\")\n",
    "\n",
    "# Recommendation\n",
    "if near_zero + near_one > len(data) * 0.05:\n",
    "    recommendation = \"Consider trimming extreme scores\"\n",
    "else:\n",
    "    recommendation = \"No trimming needed\"\n",
    "\n",
    "print(f\"\\nüí° Recommendation: {recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 8: Save Propensity Scores\n",
    "\n",
    "Now we'll save the propensity scores and model for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data with propensity scores\n",
    "output_path = '/Users/dustinober/Projects/Causal-Impact-of-Email-Marketing-on-Purchase-Behavior/data/processed/data_with_propensity_scores.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"\\nüíæ Data with propensity scores saved:\")\n",
    "print(f\"   {output_path}\")\n",
    "print(f\"   Shape: {data.shape}\")\n",
    "print(f\"   New column: 'propensity_score'\")\n",
    "\n",
    "# Save model parameters\n",
    "model_info = {\n",
    "    'features': features,\n",
    "    'model_coefficients': model.coef_[0].tolist(),\n",
    "    'model_intercept': model.intercept_[0].tolist(),\n",
    "    'auc': float(auc),\n",
    "    'scaler_mean': scaler.mean_.tolist(),\n",
    "    'scaler_scale': scaler.scale_.tolist(),\n",
    "    'common_support': {\n",
    "        'min_treated': float(min_treated),\n",
    "        'max_treated': float(max_treated),\n",
    "        'min_control': float(min_control),\n",
    "        'max_control': float(max_control),\n",
    "        'overlap_min': float(overlap_min),\n",
    "        'overlap_max': float(overlap_max)\n",
    "    }\n",
    "}\n",
    "\n",
    "model_path = '/Users/dustinober/Projects/Causal-Impact-of-Email-Marketing-on-Purchase-Behavior/data/processed/propensity_model.json'\n",
    "with open(model_path, 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "print(f\"\\nüíæ Model parameters saved:\")\n",
    "print(f\"   {model_path}\")\n",
    "\n",
    "# Verify files\n",
    "import os\n",
    "print(f\"\\n‚úÖ Files created:\")\n",
    "print(f\"   ‚úì Data file: {os.path.exists(output_path)} ({os.path.getsize(output_path)/1024/1024:.1f} MB)\")\n",
    "print(f\"   ‚úì Model file: {os.path.exists(model_path)} ({os.path.getsize(model_path):,} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 9: Summary and Interpretation\n",
    "\n",
    "Let's summarize what we've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROPENSITY SCORE ESTIMATION - SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Model Performance:\")\n",
    "print(f\"   AUC: {auc:.3f} ({performance})\")\n",
    "print(f\"   Sample size: {len(data):,} observations\")\n",
    "print(f\"   Treatment rate: {data['received_email'].mean():.1%}\")\n",
    "\n",
    "print(f\"\\nüìè Propensity Scores:\")\n",
    "print(f\"   Range: [{data['propensity_score'].min():.3f}, {data['propensity_score'].max():.3f}]\")\n",
    "print(f\"   Mean (treated): {treated_scores.mean():.3f}\")\n",
    "print(f\"   Mean (control): {control_scores.mean():.3f}\")\n",
    "print(f\"   Difference: {treated_scores.mean() - control_scores.mean():.3f}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è  Common Support:\")\n",
    "print(f\"   Overlap: [{overlap_min:.3f}, {overlap_max:.3f}]\")\n",
    "print(f\"   Units without support: {no_support:,} ({no_support/len(data)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nüéØ Key Drivers of Email Assignment:\")\n",
    "feature_importance = sorted(zip(features, abs(model.coef_[0])), \n",
    "                           key=lambda x: x[1], reverse=True)\n",
    "for i, (feature, importance) in enumerate(feature_importance, 1):\n",
    "    coef = model.coef_[0][features.index(feature)]\n",
    "    direction = \"‚Üë\" if coef > 0 else \"‚Üì\"\n",
    "    print(f\"   {i}. {feature}: {direction} (|coef| = {importance:.3f})\")\n",
    "\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "print(f\"   1. Days since last purchase is STRONGEST predictor\")\n",
    "print(f\"      ‚Üí Recent buyers much more likely to receive emails\")\n",
    "print(f\"   2. Total past purchases also important\")\n",
    "print(f\"      ‚Üí Frequent buyers get more emails\")\n",
    "print(f\"   3. Model has moderate predictive power (AUC = {auc:.3f})\")\n",
    "print(f\"   4. Good common support - most units can be matched\")\n",
    "print(f\"   5. Propensity scores ready for causal inference!\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. ‚úÖ Propensity scores estimated\")\n",
    "print(f\"   2. ‚úÖ Common support verified\")\n",
    "print(f\"   3. ‚úÖ Model diagnostics complete\")\n",
    "print(f\"   4. üéØ Ready for Propensity Score Matching!\")\n",
    "print(f\"   5. üéØ Or Inverse Probability Weighting!\")\n",
    "print(f\"   6. üéØ Or Stratification on propensity scores!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Key Takeaways\n",
    "\n",
    "### 1. **Propensity Scores Reduce Dimensionality**\n",
    "- Replace 5 covariates with 1 score\n",
    "- Enable matching, weighting, stratification\n",
    "- Make causal inference feasible\n",
    "\n",
    "### 2. **Model Performance Matters**\n",
    "- AUC measures predictive power\n",
    "- Higher AUC = better discrimination\n",
    "- Our AUC = 0.661 (moderate)\n",
    "\n",
    "### 3. **Common Support is Critical**\n",
    "- Must have overlap in propensity scores\n",
    "- Units without support cannot be matched\n",
    "- Check overlap before analysis\n",
    "\n",
    "### 4. **Feature Interpretation**\n",
    "- Negative coef: Higher value ‚Üí Lower email probability\n",
    "- Positive coef: Higher value ‚Üí Higher email probability\n",
    "- Odds ratios show effect magnitude\n",
    "\n",
    "### 5. **Ready for Causal Inference**\n",
    "- Propensity scores estimated ‚úì\n",
    "- Diagnostics complete ‚úì\n",
    "- Data saved ‚úì\n",
    "- Can now apply matching, weighting, etc.\n",
    "\n",
    "### 6. **Why This Matters**\n",
    "- **Before**: Naive comparison shows 16.0% effect (biased!)\n",
    "- **After**: Propensity scores enable causal inference\n",
    "- **Goal**: Recover true 9.5% causal effect!\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next: Propensity Score Matching\n",
    "\n",
    "Now that we have propensity scores, we can:\n",
    "1. **Match** treated and control units with similar scores\n",
    "2. **Calculate** treatment effect on matched sample\n",
    "3. **Validate** by checking covariate balance\n",
    "4. **Recover** the true causal effect!\n",
    "\n",
    "This is the foundation for modern causal inference!\n",
    "\n",
    "---\n",
    "\n",
    "**Remember: Propensity scores are the bridge from correlation to causation!** ‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
